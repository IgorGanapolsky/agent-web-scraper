# Agent Web Scraper

A powerful web scraping application built with Python and Streamlit that allows you to search and scrape web content efficiently.

## Features

- ğŸ” Search web content using SerpAPI
- ğŸŒ Scrape headers and metadata from web pages
- ğŸ“Š Present results in a structured format
- ğŸ“¥ Export results to Excel
- ğŸš« Built-in protection against anti-bot measures
- âš¡ Real-time progress updates

## Architecture

```
app/
â”œâ”€â”€ config/              # Configuration files
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logging.py      # Logging configuration
â”‚   â””â”€â”€ settings.py     # Application settings
â”œâ”€â”€ core/               # Core functionality
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ undetected_scraper.py  # Web scraping engine
â”œâ”€â”€ utils/              # Utility functions
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ env_utils.py    # Environment utilities
â””â”€â”€ web/                # Web interface
    â”œâ”€â”€ __init__.py
    â””â”€â”€ app.py          # Streamlit application
```

## Dependencies

- Python 3.9+
- beautifulsoup4: Web scraping
- requests: HTTP client
- python-dotenv: Environment management
- pydantic: Data validation
- streamlit: Web interface
- google-search-results: SerpAPI client
- pandas: Data processing

## Setup

1. Clone the repository:
```bash
git clone https://github.com/yourusername/agent-web-scraper.git
cd agent-web-scraper
```

2. Create and activate a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: .\venv\Scripts\activate
```

3. Install dependencies:
```bash
python -m pip install -r requirements.txt
```

4. Create a `.env` file and add your SerpAPI key:
```
SERPAPI_KEY=your_serpapi_key_here
```

## Usage

1. Start the application:
```bash
streamlit run app/web/app.py
```

2. Enter a search term in the web interface
3. Configure advanced options if needed
4. Click "Search and Scrape" to begin
5. Monitor progress in real-time
6. Export results to Excel when complete

## Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## License

MIT License - see LICENSE file for details