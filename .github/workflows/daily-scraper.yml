name: Daily Reddit Scraper

on:
  schedule:
    # Run daily at 8:00 AM UTC (adjust timezone as needed)
    - cron: '0 8 * * *'
  workflow_dispatch: # Allow manual triggers

jobs:
  scrape-reddit:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install Hatch
      run: pip install hatch

    - name: Install dependencies
      run: hatch env create

    - name: Run Reddit Scraper
      env:
        SERPAPI_KEY: ${{ secrets.SERPAPI_KEY }}
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        GSPREAD_CREDENTIALS_PATH: secrets/gsheet_service_account.json
        REDDIT_CLIENT_ID: ${{ secrets.REDDIT_CLIENT_ID }}
        REDDIT_CLIENT_SECRET: ${{ secrets.REDDIT_CLIENT_SECRET }}
        REDDIT_USERNAME: ${{ secrets.REDDIT_USERNAME }}
        REDDIT_PASSWORD: ${{ secrets.REDDIT_PASSWORD }}
        REDDIT_USER_AGENT: ${{ secrets.REDDIT_USER_AGENT }}
        ZOHO_APP_PASSWORD: ${{ secrets.ZOHO_APP_PASSWORD }}
      run: |
        # Create secrets directory and credentials file
        mkdir -p secrets
        echo '${{ secrets.GSPREAD_CREDENTIALS_JSON }}' > secrets/gsheet_service_account.json

        # Run the scraper with rotating query
        hatch run python run.py
